{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1dc493",
   "metadata": {},
   "source": [
    "### RAG PIPELINE - Data ingestion to Vector DB pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4fc55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain_community in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (0.4)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (1.0.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (0.4.36)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain_community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_community) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (3.6)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (1.26.20)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain) (1.0.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.36)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.7)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.6)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.26.20)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /Users/adityasingh/Library/Python/3.12/lib/python/site-packages (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community\n",
    "%pip install langchain\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c8de65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasingh/Library/Python/3.12/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #new version langchain.text_splitter becomes langchain_text_splitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b18e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all the PDFs in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # find all pdfs (recursive)\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"‚úîÔ∏è Loaded {len(documents)} pages from {pdf_file.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to process {pdf_file.name}: {str(e)}\")\n",
    "\n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0cdc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 PDF files to process\n",
      "\n",
      "Processing pdf1.pdf\n",
      "‚úîÔ∏è Loaded 1 pages from pdf1.pdf\n",
      "[Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}, page_content=\"Aditya  Kumar  \\n üìçBengaluru,IN üìû+917061939341 ‚úâseemeadit21824@gmail.com  GitHub  Linkedin\\nSummary  Passionate  MERN  stack  developer  with  proÔ¨Åciency  in  data  structures  &  algorithms ,  and  basic  machine  learning.  Dedicated  to  building  scalable  web  applications,  optimizing  performance,  and  leveraging  technology  to  create  innovative,  real-world  solutions  that  drive  meaningful  impact.   \\nSkills \\n‚óè  Programming  Languages :  |  Python  |  C  |  C++  |  Java  |  JavaScript  |  SQL  |  PHP  |  ‚óè  Frontend  Technologies :  |  HTML  |  Bootstrap  |  JS  |  TailwindCSS  |  React  |  ‚óè  Backend  Technologies :  |  Flask  |  Node.js  |  Express.js  |  RESTful  API  |  AWS  ‚óè  Database  Technologies :  |  SQL(MySQL)  |  MongoDB  |  ‚óè  Developer  Tools :  |  Postman  |  Tableau  |  Git  &  GitHub  |  n8n  ‚óè  Data  Visualization  Libraries :  |  Matplotlib  |  Seaborn  |  Plotly  Express  |  ‚óè  ML  Frameworks :  |  NumPy  |  Pandas  |  Scikit-learn  |  ‚óè  Operating  Systems :  |  macOS  |  Linux  |  Windows  |  \\nProjects  Movie  Recommendation  Bot  \\n‚óè\\n \\nTech  Stack\\n:\\n \\nImplemented\\n \\nusing\\n \\nPython\\n \\nand\\n \\nScikit-learn\\n \\nfor\\n \\nseamless\\n \\ninteraction.\\n ‚óè  Personalized  Movie  Recommendations :  Uses  K-Nearest  Neighbors  (KNN)  to  suggest  movies  \\nbased\\n \\non\\n \\nuser\\n \\npreferences\\n \\nand\\n \\nsimilarity\\n \\nscores.\\n ‚óè  Content-Based  Filtering :  Recommends  movies  by  analyzing  genres  and  user  viewing  history .  Disaster  Response  &  Management\\n \\n‚óè\\n \\nA  system  designed  for  effective  disaster  response  and  management\\n ‚óè  Developed  a  Disaster  Response  and  Management  System  using  the  MERN  stack  with  NASA  and  \\nOpenWeather\\n \\nAPIs\\n \\nfor\\n \\nreal-time\\n \\ndisaster\\n \\ntracking.\\n ‚óè  Implemented  interactive  maps  and  secure  role-based  access  via  JWT  authentication .   \\nEducation  New  Horizon  College  of  Engineering                                                              \\nBachelor\\n \\nof\\n \\nEngineering\\n \\nin\\n \\nCSE\\n \\n(Data\\n \\nScience)\\n                                                                           \\n CGPA  :  9.28(  Till  4 ·µó ∞   Sem)                                                                                          \\nExpected\\n \\nby\\n \\nAugust\\n \\n2027\\n                                                                                       \\n  \\nAchievements  \\n2nd  Prize  ‚Äì  Tech  Olympics                                                                               2nd  Prize  Hackathon  'Code  Battle  -2k25'  20th  ISTE  Karnataka  State  Student  Convention  2024-25               24-Hour  National  Hackathon  by  VDRIT                                   New  Horizon  College  of  Engineering,                                                   IEEE  &  IEEE  Mangalore  Subsection,   March  2025                                                                                                                     March  2025   \\nCertiÔ¨Åcations  \\n‚óè  The  Complete  Python  Pro  Bootcamp  (Udemy  Link)  ‚Äì  Python  Programming,  Data  Visualization,  Web  Development,  GUI\")]\n"
     ]
    }
   ],
   "source": [
    "all_pdf_documents = process_all_pdfs('../data/')\n",
    "print(all_pdf_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417219d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}, page_content=\"Aditya  Kumar  \\n üìçBengaluru,IN üìû+917061939341 ‚úâseemeadit21824@gmail.com  GitHub  Linkedin\\nSummary  Passionate  MERN  stack  developer  with  proÔ¨Åciency  in  data  structures  &  algorithms ,  and  basic  machine  learning.  Dedicated  to  building  scalable  web  applications,  optimizing  performance,  and  leveraging  technology  to  create  innovative,  real-world  solutions  that  drive  meaningful  impact.   \\nSkills \\n‚óè  Programming  Languages :  |  Python  |  C  |  C++  |  Java  |  JavaScript  |  SQL  |  PHP  |  ‚óè  Frontend  Technologies :  |  HTML  |  Bootstrap  |  JS  |  TailwindCSS  |  React  |  ‚óè  Backend  Technologies :  |  Flask  |  Node.js  |  Express.js  |  RESTful  API  |  AWS  ‚óè  Database  Technologies :  |  SQL(MySQL)  |  MongoDB  |  ‚óè  Developer  Tools :  |  Postman  |  Tableau  |  Git  &  GitHub  |  n8n  ‚óè  Data  Visualization  Libraries :  |  Matplotlib  |  Seaborn  |  Plotly  Express  |  ‚óè  ML  Frameworks :  |  NumPy  |  Pandas  |  Scikit-learn  |  ‚óè  Operating  Systems :  |  macOS  |  Linux  |  Windows  |  \\nProjects  Movie  Recommendation  Bot  \\n‚óè\\n \\nTech  Stack\\n:\\n \\nImplemented\\n \\nusing\\n \\nPython\\n \\nand\\n \\nScikit-learn\\n \\nfor\\n \\nseamless\\n \\ninteraction.\\n ‚óè  Personalized  Movie  Recommendations :  Uses  K-Nearest  Neighbors  (KNN)  to  suggest  movies  \\nbased\\n \\non\\n \\nuser\\n \\npreferences\\n \\nand\\n \\nsimilarity\\n \\nscores.\\n ‚óè  Content-Based  Filtering :  Recommends  movies  by  analyzing  genres  and  user  viewing  history .  Disaster  Response  &  Management\\n \\n‚óè\\n \\nA  system  designed  for  effective  disaster  response  and  management\\n ‚óè  Developed  a  Disaster  Response  and  Management  System  using  the  MERN  stack  with  NASA  and  \\nOpenWeather\\n \\nAPIs\\n \\nfor\\n \\nreal-time\\n \\ndisaster\\n \\ntracking.\\n ‚óè  Implemented  interactive  maps  and  secure  role-based  access  via  JWT  authentication .   \\nEducation  New  Horizon  College  of  Engineering                                                              \\nBachelor\\n \\nof\\n \\nEngineering\\n \\nin\\n \\nCSE\\n \\n(Data\\n \\nScience)\\n                                                                           \\n CGPA  :  9.28(  Till  4 ·µó ∞   Sem)                                                                                          \\nExpected\\n \\nby\\n \\nAugust\\n \\n2027\\n                                                                                       \\n  \\nAchievements  \\n2nd  Prize  ‚Äì  Tech  Olympics                                                                               2nd  Prize  Hackathon  'Code  Battle  -2k25'  20th  ISTE  Karnataka  State  Student  Convention  2024-25               24-Hour  National  Hackathon  by  VDRIT                                   New  Horizon  College  of  Engineering,                                                   IEEE  &  IEEE  Mangalore  Subsection,   March  2025                                                                                                                     March  2025   \\nCertiÔ¨Åcations  \\n‚óè  The  Complete  Python  Pro  Bootcamp  (Udemy  Link)  ‚Äì  Python  Programming,  Data  Visualization,  Web  Development,  GUI\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09da8ca",
   "metadata": {},
   "source": [
    "STEP 2 : Text Splitting get into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7774578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents, chuck_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks....\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chuck_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function = len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \",\"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)}\")\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk: \")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    return split_docs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d90e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 5\n",
      "\n",
      "Example chunk: \n",
      "Content: Aditya  Kumar  \n",
      " üìçBengaluru,IN üìû+917061939341 ‚úâseemeadit21824@gmail.com  GitHub  Linkedin\n",
      "Summary  Passionate  MERN  stack  developer  with  proÔ¨Åciency  in  data  structures  &  algorithms ,  and  bas...\n",
      "Metadata: {'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}\n",
      "[Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}, page_content='Aditya  Kumar  \\n üìçBengaluru,IN üìû+917061939341 ‚úâseemeadit21824@gmail.com  GitHub  Linkedin\\nSummary  Passionate  MERN  stack  developer  with  proÔ¨Åciency  in  data  structures  &  algorithms ,  and  basic  machine  learning.  Dedicated  to  building  scalable  web  applications,  optimizing  performance,  and  leveraging  technology  to  create  innovative,  real-world  solutions  that  drive  meaningful  impact.   \\nSkills'), Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}, page_content='Skills \\n‚óè  Programming  Languages :  |  Python  |  C  |  C++  |  Java  |  JavaScript  |  SQL  |  PHP  |  ‚óè  Frontend  Technologies :  |  HTML  |  Bootstrap  |  JS  |  TailwindCSS  |  React  |  ‚óè  Backend  Technologies :  |  Flask  |  Node.js  |  Express.js  |  RESTful  API  |  AWS  ‚óè  Database  Technologies :  |  SQL(MySQL)  |  MongoDB  |  ‚óè  Developer  Tools :  |  Postman  |  Tableau  |  Git  &  GitHub  |  n8n  ‚óè  Data  Visualization  Libraries :  |  Matplotlib  |  Seaborn  |  Plotly  Express  |  ‚óè  ML  Frameworks :  |  NumPy  |  Pandas  |  Scikit-learn  |  ‚óè  Operating  Systems :  |  macOS  |  Linux  |  Windows  |  \\nProjects  Movie  Recommendation  Bot  \\n‚óè\\n \\nTech  Stack\\n:\\n \\nImplemented\\n \\nusing\\n \\nPython\\n \\nand\\n \\nScikit-learn\\n \\nfor\\n \\nseamless\\n \\ninteraction.\\n ‚óè  Personalized  Movie  Recommendations :  Uses  K-Nearest  Neighbors  (KNN)  to  suggest  movies  \\nbased\\n \\non\\n \\nuser\\n \\npreferences\\n \\nand\\n \\nsimilarity\\n \\nscores.'), Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}, page_content='for\\n \\nseamless\\n \\ninteraction.\\n ‚óè  Personalized  Movie  Recommendations :  Uses  K-Nearest  Neighbors  (KNN)  to  suggest  movies  \\nbased\\n \\non\\n \\nuser\\n \\npreferences\\n \\nand\\n \\nsimilarity\\n \\nscores.\\n ‚óè  Content-Based  Filtering :  Recommends  movies  by  analyzing  genres  and  user  viewing  history .  Disaster  Response  &  Management\\n \\n‚óè\\n \\nA  system  designed  for  effective  disaster  response  and  management\\n ‚óè  Developed  a  Disaster  Response  and  Management  System  using  the  MERN  stack  with  NASA  and  \\nOpenWeather\\n \\nAPIs\\n \\nfor\\n \\nreal-time\\n \\ndisaster\\n \\ntracking.\\n ‚óè  Implemented  interactive  maps  and  secure  role-based  access  via  JWT  authentication .   \\nEducation  New  Horizon  College  of  Engineering                                                              \\nBachelor\\n \\nof\\n \\nEngineering\\n \\nin\\n \\nCSE\\n \\n(Data\\n \\nScience)'), Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}, page_content=\"Bachelor\\n \\nof\\n \\nEngineering\\n \\nin\\n \\nCSE\\n \\n(Data\\n \\nScience)\\n                                                                           \\n CGPA  :  9.28(  Till  4 ·µó ∞   Sem)                                                                                          \\nExpected\\n \\nby\\n \\nAugust\\n \\n2027\\n                                                                                       \\n  \\nAchievements  \\n2nd  Prize  ‚Äì  Tech  Olympics                                                                               2nd  Prize  Hackathon  'Code  Battle  -2k25'  20th  ISTE  Karnataka  State  Student  Convention  2024-25               24-Hour  National  Hackathon  by  VDRIT                                   New  Horizon  College  of  Engineering,                                                   IEEE  &  IEEE  Mangalore  Subsection,   March  2025                                                                                                                     March  2025   \\nCertiÔ¨Åcations\"), Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': '1NH23CD194_Aditya_Kumar', 'source': '../data/pdf/pdf1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'pdf1.pdf', 'file_type': 'pdf'}, page_content='CertiÔ¨Åcations  \\n‚óè  The  Complete  Python  Pro  Bootcamp  (Udemy  Link)  ‚Äì  Python  Programming,  Data  Visualization,  Web  Development,  GUI')]\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83980083",
   "metadata": {},
   "source": [
    "STEP 3: Embedding (converting text into vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9063a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185a4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded Successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x17b6de5d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pydantic_core.core_schema import none_schema\n",
    "\n",
    "\n",
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using Sentence Transformer\"\"\"\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "            Initialize the embedding manager\n",
    "            Args:\n",
    "                model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None #later on we are initialize the model\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded Successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\") #by default dim : 384\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}:{e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts:List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Generate embedding for a list of texts\n",
    "\n",
    "            Args:\n",
    "                texts:List  of text strings to embed\n",
    "            Returns:\n",
    "                numpy array of embeddings with shape(len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not found!!!\")\n",
    "        print(f\"Generating embeddings for {len(texts)} texts\")\n",
    "        embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "# initialize the embedding manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edd4d6",
   "metadata": {},
   "source": [
    "## STEP 4 : Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d38895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    def __init__(self, collection_name : str=\"pdf_documents\", persist_directory:str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "\n",
    "        Args:\n",
    "            collection_name : Name of the chromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "    \n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection.\"\"\"\n",
    "        try:\n",
    "            # create persistent chromaDb client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "\n",
    "            #Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata = {\"desc\":\"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection : {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in initializing vector store: {e}\")\n",
    "            raise\n",
    "# to add documents\n",
    "\n",
    "    def add_documents(self, documents : List[Any], embeddings:np.ndarray):\n",
    "        \"\"\"\n",
    "            Add docs and their embeddins in the vector store\n",
    "\n",
    "            Args:\n",
    "                documents : List of langchain documents\n",
    "                embeddings : Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        print(f\"Adding {len(documents)} documents to vector store\")\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i,(doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generating unique Id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "    # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids, \n",
    "                embeddings = embeddings_list,\n",
    "                metadatas = metadatas,\n",
    "                documents = documents_text\n",
    "            )\n",
    "            print(f\"Successfully Added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection : {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector Store: {e} \")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27f3e355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized collection: pdf_documents\n",
      "Existing documents in collection : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x17f20c4d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48017314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 5 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (5, 384)\n",
      "Adding 5 documents to vector store\n",
      "Successfully Added 5 documents to vector store\n",
      "Total documents in collection : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "### Generate the embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "### store in the vector database\n",
    "vectorstore.add_documents(chunks, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc692ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
